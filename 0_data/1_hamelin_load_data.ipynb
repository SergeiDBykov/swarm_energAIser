{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import data_path, set_mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "from tables import NaturalNameWarning\n",
    "warnings.filterwarnings('ignore', category=NaturalNameWarning)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions to load data for Hamelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_timeseries_s22_year(resol: str = '60min', year: str = '2018') -> pd.DataFrame:\n",
    "    data_path_s22 = data_path+'Hamelin_orig/'\n",
    "    print(f'READ FROM {data_path_s22}')\n",
    "    assert resol in ['10s', '1min', '15min', '60min'], f'Resolution {resol} is not available. Please choose from 10s, 1min, 15min, 60min'\n",
    "\n",
    "    available_home_numbers = ['3', '4', '5',  '7', '8', '9', '10', '11', '12', '14', '16', '18',\n",
    "                                '19', '20', '21', '22', '23', '27', '28', '29', '30', '31', '32',\n",
    "                                '34', '35', '36', '37', '38', '39', '40']\n",
    "    available_home_numbers_PV = ['13','15', '26', '33']\n",
    "\n",
    "    #house 24 and 25  ignored since they have less than 2 years of data\n",
    "    #house 6,17 removed since it has only around 50% of data\n",
    "\n",
    "\n",
    "    filename_sub = data_path_s22+year+'_data_'+'spatial.hdf5'\n",
    "    df_substation = pd.read_hdf(filename_sub, key=f'SUBSTATION/{resol}')\n",
    "    df_substation.index = pd.to_datetime(df_substation.index, unit = 's')\n",
    "    df_substation = df_substation[['P_TOT']]\n",
    "    df_substation.columns = ['P_substation']\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for house_num in available_home_numbers:\n",
    "\n",
    "\n",
    "        filename = data_path_s22+year+'_data_'+resol+'.hdf5'\n",
    "        df_1 = pd.read_hdf(filename, key=f'NO_PV/SFH{house_num}/HOUSEHOLD') #HEATPUMP and HOUSEHOLD are summed\n",
    "        df_1.index = pd.to_datetime(df_1.index, unit = 's')\n",
    "        df_1 = df_1[[f'P_TOT']]\n",
    "        df_1.columns = [f'P_HOME_{house_num}']\n",
    "\n",
    "        df_2 = pd.read_hdf(filename, key=f'NO_PV/SFH{house_num}/HEATPUMP')\n",
    "        df_2.index = pd.to_datetime(df_2.index, unit = 's')\n",
    "        df_2 = df_2[[f'P_TOT']]\n",
    "        df_2.columns = [f'P_HEAT_{house_num}']\n",
    "\n",
    "\n",
    "        df_comb = df_1.join(df_2)\n",
    "        df_comb['P_TOT_'+house_num] = df_comb['P_HOME_'+house_num] + df_comb['P_HEAT_'+house_num]\n",
    "\n",
    "        df_list.append(df_comb)\n",
    "    \n",
    "    for house_num in available_home_numbers_PV:\n",
    "            \n",
    "        filename = data_path_s22+year+'_data_'+resol+'.hdf5'\n",
    "        df_1 = pd.read_hdf(filename, key=f'WITH_PV/SFH{house_num}/HOUSEHOLD')\n",
    "        df_1.index = pd.to_datetime(df_1.index, unit = 's')\n",
    "        df_1 = df_1[[f'P_TOT']]\n",
    "        df_1.columns = [f'P_HOME_{house_num}']\n",
    "\n",
    "\n",
    "        df_2 = pd.read_hdf(filename, key=f'WITH_PV/SFH{house_num}/HEATPUMP')\n",
    "        df_2.index = pd.to_datetime(df_2.index, unit = 's')\n",
    "        df_2 = df_2[[f'P_TOT']]\n",
    "        df_2.columns = [f'P_HEAT_{house_num}']\n",
    "\n",
    "\n",
    "        df_comb = df_1.join(df_2)\n",
    "        df_comb['P_TOT_'+house_num] = df_comb['P_HOME_'+house_num] + df_comb['P_HEAT_'+house_num]\n",
    "\n",
    "        df_list.append(df_comb)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    df = pd.concat(df_list, axis=1)\n",
    "    df = pd.concat([df, df_substation], axis=1)\n",
    "\n",
    "    print(f'DATA LOADED FROM {data_path_s22}. \\n Houses number removed: 6, 17, 24, 25. \\n Houses with PV: {available_home_numbers_PV} \\n HOUSEHOLD and HEATPUMP energy consumption are separated. \\n Resolution: {resol} \\n Years: {year}')\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_timeseries_s22(resol: str = '60min')-> pd.DataFrame:\n",
    "    df_2018 = read_timeseries_s22_year(resol=resol, year='2018')\n",
    "    df_2019 = read_timeseries_s22_year(resol=resol, year='2019')\n",
    "    df_2020 = read_timeseries_s22_year(resol=resol, year='2020')\n",
    "    df = pd.concat([df_2018, df_2019, df_2020], axis=0)\n",
    "\n",
    "    df.dropna(inplace=True, how='all')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_weather_s22(resol = '60min'):\n",
    "    data_path_s22 = data_path+'Hamelin_orig/'\n",
    "    print(f'READ FROM {data_path_s22}')\n",
    "    \n",
    "    years = ['2018', '2019', '2020']\n",
    "    cols = ['APPARENT_TEMPERATURE_TOTAL', 'ATMOSPHERIC_PRESSURE_TOTAL', 'PRECIPITATION_RATE_TOTAL', 'RELATIVE_HUMIDITY_TOTAL', 'SOLAR_IRRADIANCE_GLOBAL', 'TEMPERATURE_TOTAL']\n",
    "\n",
    "    cols_aliases = {'APPARENT_TEMPERATURE_TOTAL': 'WEATHER_T_APP', 'ATMOSPHERIC_PRESSURE_TOTAL': 'WEATHER_P_ATM', 'PRECIPITATION_RATE_TOTAL': 'WEATHER_PREC_RATE', 'RELATIVE_HUMIDITY_TOTAL': 'WEATHER_H_REL', 'SOLAR_IRRADIANCE_GLOBAL': 'WEATHER_I_SOLAR', 'TEMPERATURE_TOTAL': 'WEATHER_T'}\n",
    "\n",
    "    df_years = [] \n",
    "    for year in years:\n",
    "        df_list = []\n",
    "        filename = data_path_s22+year+'_weather.hdf5'\n",
    "        print(f'LOADING WEATHER: {filename}')\n",
    "        for col in cols:\n",
    "            #print(f'\\t fetching {col}...')\n",
    "            df = pd.read_hdf(filename, key=f'WEATHER_SERVICE/IN/WEATHER_{col}')\n",
    "            df.index = pd.to_datetime(df.index, unit = 's')\n",
    "            df.name = cols_aliases[col]\n",
    "            df.columns = [cols_aliases[col]]\n",
    "\n",
    "            #index has duplicates, drop them. eg in 2018, there are 40 duplicates in df_list at 22 and 23 hours. keep first\n",
    "            df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "            df.columns = [cols_aliases[col]]\n",
    "\n",
    "            df_list.append(df)\n",
    "\n",
    "        df_year = pd.concat(df_list, axis=1)\n",
    "        df_years.append(df_year)\n",
    "    \n",
    "    df = pd.concat(df_years, axis=0)\n",
    "\n",
    "    df.dropna(inplace=True, how='all')\n",
    "    df = df.resample(resol).mean()\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data for Hamelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ FROM /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/\n",
      "LOADING WEATHER: /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/2018_weather.hdf5\n",
      "LOADING WEATHER: /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/2019_weather.hdf5\n",
      "LOADING WEATHER: /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/2020_weather.hdf5\n",
      "READ FROM /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/\n",
      "DATA LOADED FROM /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/. \n",
      " Houses number removed: 6, 17, 24, 25. \n",
      " Houses with PV: ['13', '15', '26', '33'] \n",
      " HOUSEHOLD and HEATPUMP energy consumption are separated. \n",
      " Resolution: 60min \n",
      " Years: 2018\n",
      "READ FROM /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/\n",
      "DATA LOADED FROM /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/. \n",
      " Houses number removed: 6, 17, 24, 25. \n",
      " Houses with PV: ['13', '15', '26', '33'] \n",
      " HOUSEHOLD and HEATPUMP energy consumption are separated. \n",
      " Resolution: 60min \n",
      " Years: 2019\n",
      "READ FROM /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/\n",
      "DATA LOADED FROM /Users/sdbykov/not_work/swarm_energAIser/0_data/Hamelin_orig/. \n",
      " Houses number removed: 6, 17, 24, 25. \n",
      " Houses with PV: ['13', '15', '26', '33'] \n",
      " HOUSEHOLD and HEATPUMP energy consumption are separated. \n",
      " Resolution: 60min \n",
      " Years: 2020\n"
     ]
    }
   ],
   "source": [
    "weather = read_weather_s22()\n",
    "\n",
    "energy = read_timeseries_s22()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for google drive folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude May-June 2019 data for home # 34\n",
    "energy.loc['2019-05-01':'2019-06-01', ['P_HOME_34',\t'P_HEAT_34',\t'P_TOT_34',]] = np.nan\n",
    "\n",
    "#replace values  with nan if their difference with previous value is exactly 0\n",
    "energy_diff = energy.diff()\n",
    "for col in energy.columns:\n",
    "    energy.loc[energy_diff[col] == 0, col] = np.nan\n",
    "\n",
    "\n",
    "#drop data before 2018-05-18 - there are gaps in all data\n",
    "energy = energy.query('index > \"2018-05-18\"')\n",
    "weather = weather.query('index > \"2018-05-18\"')\n",
    "\n",
    "energy.to_pickle(data_path + 'Hamelin_drive/hamelin_energy.pkl')\n",
    "weather.to_pickle(data_path + 'Hamelin_drive/hamelin_weather.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1dc9197fbdaf2df20a0ea77561d79844f791293e1aa1b8fac12d88bf49496cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
